<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>QVIM </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo -->
					<div id="logo">
						<span class="image avatar48"><img src="images/avatar.jpg" alt="" /></span>
						<h1 id="title" style="font-size: 1.8em;">Querying by Vocal Imitation</h1>
						<p style="font-size: 1.2em;">AES AIMLA Challenge 2025</p>
					</div>

						<nav id="nav">
							<ul>
								<li><a href="#top" id="top-link"><span class="icon solid fa-home">Home</span></a></li>
								<li><a href="#portfolio" id="portfolio-link"><span class="icon solid fa-info-circle">Challenge Description</span></a></li>
								<li><a href="#about" id="about-link"><span class="icon solid fa-file-alt">Submissions</span></a></li>
								<li><a href="#baselines" id="baselines-link"><span class="icon solid fa-chart-bar">Baselines</span></a></li>
								<li><a href="#datasets" id="datasets-link"><span class="icon solid fa-database"></span> Datasets</a></li>
								<li><a href="#papers" id="papers-link"><span class="icon solid fa-file-alt"></span> Papers</a></li>
								<li><a href="#prizes" id="baselines-link"><span class="icon solid fa-trophy">Prizes</span></a></li>
								<li><a href="#team" id="team-link"><span class="icon solid fa-users">Team Members</span></a></li>
								<li><a href="#Partners" id="partners-link"><span class="class=icon solid fa-handshake">Promotion Partner</span></a></li>
								<li><a href="#Registration" id="registration-link"><span class="icon solid fa-check">Registration</span></a></li>
								<li><a href="#contact" id="contact-link"><span class="icon solid fa-envelope">Contact</span></a></li>
							</ul>
						</nav>					

				</div>

				<div class="bottom">

					<!-- Social Icons -->
					<ul class="icons">
						<li><a href="https://x.com/QvimA10120" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://www.facebook.com/AES.org" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						<li><a href="https://github.com/qvim-aes" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="mailto:qvim.aes@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>


				</div>

			</div>

		<!-- Main -->
			<div id="main">

				<section id="top" class="one cover">
					<div class="container">
				
						<header>
							<img src="images/challengeintro.jpg" alt="Querying by Vocal Imitation 2025 Challenge" style="max-width: 100%; height: auto;" />
						</header>
				
						<footer>
							<a href="#portfolio" class="button scrolly"> Learn more</a>
						</footer>
				
					</div>
				</section>

				<!-- Challenge Description -->
					<section id="portfolio" class="two">
						<div class="container">

							<header>
								<h2 class="text-4xl font-bold">Challenge Description</h2>
							</header>

							<p> Query by Vocal Imitation enables users to search a database of sounds by recording a vocal impression of the
								desired sound. The system then retrieves sounds similar to the users recording. This offers sound designers an
								intuitively expressive way of navigating large sound effects databases. We invite participants to submit systems that
								accept a vocal imitation query and retrieve a perceptually similar recording from a large database of sound effects.
								Final rankings of submissions will be determined by a subjective evaluation using a larger, unlabeled dataset.
								This challenge is part of the <strong>AES AIMLA Challenge 2025</strong>. The key dates are as follows:
                                <ul style="font-size: 1.0em; font-weight: bold;">
									<li>Challenge start: April 1, 2025</li>
									<li>Challenge end: June 15, 2025</li>
									<li>Challenge results announcement: July 15, 2025</li>
								</ul>
								Conference official website: <a href="https://aes2.org/event-extra/2025-aes-international-conference-on-artificial-intelligence-and-machine-learning-for-audio/" target="_blank"> AES AIMLA 2025</a>
							</p>

							<div class="row">
								<div class="col-4 col-12-mobile">
									<article class="item">
										
	
									</article>
									<article class="item">
									
									</article>
								</div>
								
							</div>

						</div>
					</section>

				<!-- Submissions -->

				<section id="about" class="three">
					<div class="container">
						<header>
							<h2 class="text-4xl font-bold">Submissions</h2>
						</header>
				
						<p>
							Participants are required to submit a technical report detailing the datasets and methods used in development, as well as a Jupyter notebook containing the system itself.
						</p>
				
						<ul>
							<li>
								<strong>Technical Specifications: A5000, GPU memory 24GB.</strong>
							</li>
							
						</ul>
				
						<p>
							Detailed instructions are provided in the submission templates containing the baseline implementations.
							<a href="https://github.com/qvim-aes/qvim-submission" target="_blank">Learn more about the submission process here or click on the icon below</a>. The submissions will be opened two weeks before the challenge deadline, during which time participants will be able to submit their system to check that their submitted code is running correctly. Each team may submit up to three different systems.
						</p>
				
						<ul class="icons">
							<li>
							  <a href="https://github.com/qvim-aes/qvim-submission" class="icon brands fa-github fa-4x">
								<span class="label">GitHub Repo for submissions</span>
							  </a>
							</li>
						</ul>
					</div>
				</section>
				

		<!-- Baselines -->
<section id="baselines" class="four">
    <div class="container">
        <header>
			<h2 class="text-4xl font-bold">Baselines</h2>
        </header>

        <p>
           We provide a repository containing the baseline system for the AES AIMLA Challenge 2025. The architecture and the training procedure is based on <a href="https://dcase.community/documents/workshop2024/proceedings/DCASE2024Workshop_Greif_36.pdf " target="_blank"> "Improving Query-by-Vocal Imitation with Contrastive Learning and Audio Pretraining" (DCASE2025 Workshop)</a>.
		   Check the repository for the details of the baseline system. Here: <a href="https://github.com/qvim-aes/qvim-baseline" target="_blank">Baseline of QVIM</a>.
        </p>
		ul class="icons">
							<li>
							  <a href="https://github.com/qvim-aes/qvim-baseline" class="icon brands fa-github fa-4x">
								<span class="label">GitHub repo for baseline</span>
							  </a>
							</li>
						  </ul>

        <ul>
            
        </ul>
		<p>Also, here's a list of pre-trained audio embedding models that participants might find interesting.</p>
		<ul>
			<li>
                <strong>Mobile-Net:</strong> : Extracts features via a dual-encoder architecture consisting of two MobileNets pre-trained on AudioSet and fine-tuned on vocal imitations via contrastive learning. 
                <a href="https://ieeexplore.ieee.org/document/7952261" target="_blank">Learn more about MobileNet</a>.
            </li>
            <li>
                <strong>2DFT:</strong> A purely signal-processing-based representation, calculated as the 2D Fourier transform of the constant-Q transform of the audio signal.
				<a href="https://arxiv.org/abs/1001.1955" target="_blank">Learn more about 2DFT</a>.
            </li>
            <li>
                <strong>AST:</strong> <a href="https://github.com/YuanGongND/ast" target="_blank">https://github.com/YuanGongND/ast</a>
            </li>
            <li>
                <strong>BEATs:</strong> <a href="https://github.com/microsoft/unilm/tree/master/beats" target="_blank">https://github.com/microsoft/unilm/tree/master/beats</a>
            </li>
            <li>
                <strong>EfficientAT:</strong> <a href="https://github.com/fschmid56/EfficientAT" target="_blank">https://github.com/fschmid56/EfficientAT</a>
            </li>
            <li>
                <strong>PaSST:</strong> <a href="https://github.com/kkoutini/PaSST" target="_blank">https://github.com/kkoutini/PaSST</a>
            </li>
            <li>
                <strong>BYOL-A:</strong> <a href="https://github.com/nttcslab/byol-a" target="_blank">https://github.com/nttcslab/byol-a</a>
            </li>
            <li>
                <strong>PANNs:</strong> <a href="https://zenodo.org/records/3987831" target="_blank">https://zenodo.org/records/3987831</a>
            </li>
        </ul>
    </div>

</section>


<!-- Datasets -->
<section id="datasets" class="five">
    <div class="container">
        <header>
            <h2 class="text-4xl font-bold">Datasets</h2>
        </header>
		<p>Participants are welcome and encouraged to utilize any publicly available dataset. <strong>We DO NOT encourage the use of private datasets.</strong> </p>
		<p>Public Datasets:</p>
		<ul>
			<li><strong>VocalSketch:</strong> <a href="https://zenodo.org/records/1251982" target="_blank">https://zenodo.org/records/1251982</a></li>
            <li><strong>Vocal Imitation Set:</strong> <a href="https://zenodo.org/records/1340763" target="_blank">https://zenodo.org/records/1340763</a></li>
            <li><strong>VimSketch (VocalSketch+Vocal Imitation Set):</strong> <a href="https://zenodo.org/records/2596911" target="_blank">https://zenodo.org/records/2596911</a></li>
            <li><strong>AudioSet:</strong> <a href="https://research.google.com/audioset/" target="_blank">https://research.google.com/audioset/</a></li>
		</ul>
		<p> <strong>DEV Dataset Overview</strong> 

			Number of Imitations: The dataset contains a total of 985 unique imitation audio files across the three query columns (Query 1, Query 2, Query 3). 
			Number of References: The dataset includes 121 unique reference sound files listed under the Items column. 
			Matching Relationship 
			
			Each row in the CSV file maps one reference sound (Items) to up to three corresponding vocal imitation files (Query 1, Query 2, Query 3). Multiple rows may have the same reference sound but different imitation files, indicating that the same sound may have been imitated multiple times by different participants. 
			
			The DEV dataset is useful for evaluating the consistency and accuracy of vocal imitation by comparing the generated imitations with the original reference sounds. </p>
        <p>Our dataset is available for download  with the csv and the description of how the csv works in the following link:</p>
        <ul>
            <li><strong>DEV:</strong> Used for objective performance evaluation.  
                <a href="https://drive.google.com/drive/folders/11PcPIS2Z4YvfujrF40QqLDaUCFzyLvmx?usp=share_link" target="_blank">Download DEV Dataset</a>.
            </li>
            
        </ul>
    </div>
</section>

<section id="papers" class="six">
    <div class="container">
        <header>
            <h2 class="text-4xl font-bold">Papers </h2>
        </header>
		<p>We highlight some papers that participants may find relevant for this task</p>
		<ul>
            <li><strong>Greif, J., Schmid, F., Primus, P. and Widmer, G., 2024:</strong> Improving Query-by-Vocal Imitation with Contrastive Learning and Audio Pretraining. In Proceedings of the Detection and Classification of Acoustic Scenes and Events 2024 Workshop (DCASE2024), 51-55. <a href="https://dcase.community/documents/workshop2024/proceedings/DCASE2024Workshop_Greif_36.pdf" target="_blank">https://dcase.community/documents/workshop2024/proceedings/DCASE2024Workshop_Greif_36.pdf</a></li>
            <li><strong>Zhang, Y., Hu, J., Zhang, Y., Pardo, B. and Duan, Z., 2020:</strong> Vroom! a search engine for sounds by vocal imitation queries. In Proceedings of the 2020 Conference on Human Information Interaction and Retrieval (pp. 23-32). <a href="https://dl.acm.org/doi/pdf/10.1145/3343413.3377963" target="_blank">https://dl.acm.org/doi/pdf/10.1145/3343413.3377963</a></li>
            <li><strong>Pishdadian, F., Seetharaman, P., Kim, B., & Pardo, B., 2019:</strong> Classifying Non-speech Vocals: Deep vs Signal Processing Representations. In Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (DCASE2019), 194â€“198. <a href="https://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Pishdadian_51.pdf" target="_blank">https://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Pishdadian_51.pdf</a></li>
            <li><strong>Kim, B. and Pardo, B., 2019:</strong> Improving content-based audio retrieval by vocal imitation feedback. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 4100-4104). <a href="https://ieeexplore.ieee.org/abstract/document/8683461" target="_blank">https://ieeexplore.ieee.org/abstract/document/8683461</a></li>
            <li><strong>Zhang, Y., Pardo, B. and Duan, Z., 2018:</strong> Siamese style convolutional neural networks for sound search by vocal imitation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 27(2), pp.429-441. <a href="https://ieeexplore.ieee.org/abstract/document/8453811" target="_blank">https://ieeexplore.ieee.org/abstract/document/8453811</a></li>
        </ul>
    </div>
</section>

<!-- Submissions -->

<section id="prizes" class="seven">
	<div class="container">
		<header>
			<h2 class="text-4xl font-bold">Prizes</h2>
		</header>
		<header>
			<img src="images/prizes.jpg" alt="Team Members Challenge 2025" style="max-width: 100%; height: auto;" />
		</header>
	</div>
</section>




<!-- Team Members -->
<section id="team" class="eight">
    <div class="container">
        <header>
            <h2 class="text-4xl font-bold">Team Members</h2>
        </header>
        <header>
			<img src="images/team.jpg" alt="Team Members Challenge 2025" style="max-width: 100%; height: auto;" />
		</header>

    </div>
</section>

<!-- Team Members -->
<section id="Partners" class="nine">
    <div class="container">
        <header>
            <h2 class="text-4xl font-bold">Promotion Partner</h2>
        </header>
        <header>
			<img src="images/AudioProgrammer.png" alt="Promotion Partner" style="max-width: 100%; height: auto;" />
		</header>

    </div>
</section>


<!-- Registration -->
<section id="Registration" class="ten">
    <div class="container">
        <header>
            <h2 class="text-4xl font-bold">Registration</h2>
        </header>
        <p>
            Wanna participate? Let us know. Register your team by clicking the button below.
            It is important to note that the registration is free of charge.
            This form will help the organizers to keep track of the participants and send updates about the challenge.
        </p>

        <!-- Registration Button -->
        <div style="text-align: center; margin: 20px 0;">
            <a href="#google-form" class="button solid">
                <span class="icon solid fa-users"></span> Register Now
            </a>
        </div>

        <!-- Embedded Google Form -->
        <div id="google-form" style="text-align: center; margin-top: 40px;">
            <iframe 
                src="https://docs.google.com/forms/d/e/1FAIpQLSciC9xoEdsvv1dQb2VfjbeU_ZGPsDeZzUO3Kj8EVoIOACneVg/viewform?embedded=true" 
                width="640" 
                height="1683" 
                frameborder="0" 
                style="border: none; max-width: 100%;"
                allowfullscreen>
            </iframe>
        </div>
    </div>
</section>




				<!-- Contact -->
					<section id="contact" class="eleven">
						<div class="container">

							<header>
								<h2 class="text-4xl font-bold">Contact</h2>
							</header>

							<p>Got any questions?
							</p>

							<form method="post" action="mailto:qvim.aes@gmail.com">

								<div class="row">
									<div class="col-6 col-12-mobile"><input type="text" name="name" placeholder="Name" /></div>
									<div class="col-6 col-12-mobile"><input type="text" name="email" placeholder="Email" /></div>
									<div class="col-12">
										<textarea name="message" placeholder="Message"></textarea>
									</div>
									<div class="col-12">
										<input type="submit" value="Send Message" />
									</div>
								</div>
							</form>

						</div>
					</section>

			</div>

		<!-- Footer -->
			<div id="footer">

				<!-- Copyright -->
					<ul class="copyright">
						<li>&copy; All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
